#+startup:fold
# ------------------------------------------------------------------------------
GRIM: GRId submission and Monitoring scripts

gen_fcl.py, submit_job.py, list_pnfs_files.py, and friends

GRIM provides a uniform interface to various existing Mu2e tools used 
for the grid submission, makes those tools to communicate to each other, 
provides some level of bookkeeping, and significantly simplifies using GRID.

In its present state, GRIM is not a production-grade set of tools - it doesn't
have cron-based job submission and monitoring mechanisms needed at that level.

GRIM is rather a grid submission toolkit for individual users and analysis groups, 
however it easily handles bookkeeping for multiple multi-stage jobs with 
tens of thousands of segments per stage

NB: the interfaces evolve in time, the most up-to date information
on any script parameters can be found on top of every script, for example:
[[file:../scripts/submit_job.py]] - if in doubt, always check that.
* ------------------------------------------------------------------------------
* grid job submission prerequisites                                          
#+begin_src                                                                  
kinit
kx509
voms-proxy-init -noregen -rfc -voms fermilab:/fermilab/mu2e/Role=Analysis
getToken
#+end_src
* ------------------------------------------------------------------------------
* what is grim                                                               

 - _grim_ is a set of grid job submission and monitoring scripts for generating 
    analysis datasets by physics groups and individual users working on their analyses

 - where possible, _grim_ scripts provide a uniform and consistent interface 
   to the existing Mu2e tools (muse, generate_fcl, mu2egrid) 

* grim project                                                               
   A grim project describes a task of generating multiple datasets for an analysis.
   Example: https://github.com/mu2e/pipenu.git

   For example, a project may include:
   - generation of the proton interactions in the production target 
   - tracing the mu- beam and mu+ beams to the stopping target with different positioning 
     of the TS3 collimator
   - simulation of the mu- --> e- nunu and mu+ --> e+ nunu decays, 
   - hit digitization,
   - reconstruction 
   - ntupling

   Within the same project, different datasets could be independent or related to each other,
   with some datasets serving as an input for generating other datasets. 
   Examples of 'related' datasets:
 
   - example 1: 'raw data' and 'reco' datasets containing the same events
   - example 2: stage 1 and stage 2 of the Mu2e muon/pion beam tracing 
                (in general, tracing the beam from the production target to the stopping target 
                  may involve two, three, or even more stages)

   a group of related datasets is called a 'dataset family'. 

   - for a given dataset family, configurations of all respective jobs are defined 
     in a $project/datasets/$family/init_project.py file.

** project organization                                                      
- everything related to the project name=$project is stored in a subdirectory of the current work area, 
  named by this project, $project. 

  A project includes infrastructure to generate of one or several dataset 
  families and definitions of jobs to produce the corresponding datasets

  a dataset with a given dataset ID is described in a $project/datasets/$dsid subdirectory 
  and the package structure is as follows:
#+begin_quote 
  - $project 
    - datasets
        - familyID1
        - familyID2
        - ...
#+end_quote 
** project stages                                                            

- a project may include multiple stages. 
- Stages are named. It is convenient to name stages 's1', 's2', etc,
  - in this case the FCL files in the directory catalog are ordered automatically

- a stage may have one or several jobs associated with it. For example, it is convenient 
  to associate a reconstruction job and a job ntupling the reconstruction with the same stage, 
  
  - ntupling doesn't change the event content of the output
  - it is helpful to have the same dataset ID for ntuple dataset and the the ntupled dataset
** grim jobs                                                                 

- each job is configured by an FCL file stored in the *$project/datasets/$family_id* directory

- jobs are named, for a job name = *jobname* , the name of the corresponding FCL file 
  is *${stage_name}_${jobname}_${family_id}.fcl*. grim relies on that.

* [[file:workflow.org][workflow]]                                                                   
* dataset naming conventions                                                 
- dataset IDs (dsid's) used by GRIM have the following format: 

          dsid = _DDDDDbXsYZrUVCC_ 

  where the lower case characters have a special meaning and are fixed, 
  and the upper case characters should be substituted as follows:

  *DDDDD*    5 characters reserved for the physics part of the dataset ID, 
             for example, 'cele0' for conversion electrons

  *bX*       'X' in 'bX' - encodes the pileup level, 'b0' means no pileup, 
             'b1' - one batch mode pileup, etc

  *sYZ*      dataset produced at stage 'Y', stages are numbered starting from 1. 
             - Stage 'Y' produces N output datasets, 
             - 'Z' encodes the output dataset index running from 1 to N. 
             - Z=0 reserved for special cases.

  *rUVCC*    encodes information anout the code and calibrations versions and the job configuration
             - 'U' encodes calibrations :  0:perfect, 1:best, 2:startup
             - 'V' - marks the version of the reco code. It is assumed that this is a user-defined 
               versioning, with major versions captured in other parts of the filename
             - 'CC' - encodes the job configuration, by default : '00'. Defining the job configuration 
               is entirely up to the user. Default: r0000

- the dataset family name - the first 7 characters, common for all datasets of a given family (physics+pileup)
- full dataset names follow the Mu2e dataset naming convention and ahve 5 dot-separated fields: 

  dsname = xxx.$user.$dsid.$project.yyy

* large datasets                                                             
  for underlying generate_fcl, a single job size is limited by 1000 segments

  to generate FCLs for a large dataset, split it into several filesets, 
  making each fileset of 1000 files (a limit per job of Andrei's generate_fcl)
  or less, for example, 000 , 001, 002 ...

  when generating FCLs, to avoid duplication of the subrun numbers in different jobs, 
  use --first-subrun=1000 for fileset=001, --first-subrun=2000 for fileset=002 etc

  to submit a jobs for a given fileset, use the '--fileset' parameter of
  [[file:../scripts/submit_job.py][submit_job.py]] , for example:
#+begin_src
  submit_job.py --fileset=001 ....
#+end_src
  this approach is naive and straightforward, however it is efficient and 
  avoids complicated logic needed otherwise

* job recovery procedure                                                     
If several segments of a completed job have failed and need to be resubmitted, 
the recovery procedure looks as follows:

1. build an fcl tarball: (everything in [] is optional)

 grim/scripts/gen_fcl.py --project=$project --grid_id=xxxx[@jobsubxx.fnal.gov]

 ( this assumes that the status of the completed job has been checked by running 
 [[file:../scripts/check_completed_job.py][grim/scripts/check_completed_job.py]] , which builds a list of failed segments)

2. submit a recovery job:

 grim/scripts/gen_fcl.py --project=$project --recovery=grid_id=xxxx[@jobsubxx.fnal.gov]

3. use [[file:../scripts/list_pnfs_files.py][grim/scripts/list_pnfs_files.py]] with '--append' flag to update list of files produced by the job: 

 grim/scripts/list_pnfs_files.py --project=$project --grid_id=xxxx --append

* running test jobs                                                          
  test jobs are usually ran on a single file as input. By default, grim assumes
  that a job is run on a dataset consisting of many files. 

  Use 'gen_fcl.py --project=$project --nseg=2' to generate FCL's for a short test job with two segments

  Alternatively, one can describe a dataset or a fileset (a set of files) containing just one file.
  After that, all grim tools could be used, either with default parameters 
  or with the '--fileset' command line parameter of gen_fcl.py
* filesets                                                                   
  - a fileset can have any name, for example. '0001' or 'murat'
  - local file catalogs (lists of files) are stored in a $dsid/catalog directory
  - a list of files of a given dataset is stored in a file named '$dsname.files' 
  - a list of files corresponding to a given fileset is stored in a file named '$dsname.$fileset.files'
* how to diagnose errors                                                     
  - all grim scripts have a verbose more (add --verbose=1 switch)
  - run in verbose more, see which commands are executed
  - in most cases, it is sufficient to figure out what caused the error   
* job status bits                                                            
|-----+-----------------------------------------+------------------------|
| bit | meaning                                 | set by                 |
|-----+-----------------------------------------+------------------------|
| 0x0 | job is running                          |                        |
| 0x1 | job completed                           |                        |
| 0x2 | job status checked                      | check_completed_job.py |
| 0x4 | catalogs of the output datasets created | list_pnfs_files.py     |
| 0x8 | log files saved to the local disk       | copy_log_files.py      |
|-----+-----------------------------------------+------------------------|

* CPU types                                                                  
#+begin_src
condor_status -json fnpc23037  | grep Cpu 
#+end_src
|-----------+-------------------------------------------+-----------+----------------+-------------|
| node name | model name                                | CpuFamily | CpuModelNumber | comment     |
|-----------+-------------------------------------------+-----------+----------------+-------------|
| fnpc7021  | AMD Opteron(tm) Processor 6376            |        21 |              2 | the slowest |
| fnpc7516  | Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz |         6 |             62 |             |
| fnpc7591  |                                           |         6 |             62 | the slowest |
| fnpc7563  |                                           |         6 |             62 |             |
| fnpc9015  | Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz |         6 |             79 |             |
| fnpc17103 | Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz  |         6 |             85 |             |
| fnpc22030 |                                           |        25 |              1 |             |
| fnpc23037 | AMD EPYC 7502 32-Core Processor           |        25 |              1 | the fastest |
* condor utilities                                                           
** condor_q                                                                  
- reports many things, see 'condor_q --help'
- checking time consumed by the job segments: 
#+begin_src
[mu2epro@mu2egpvm05 pipenu_prof]$ condor_q --run --jobid=10774671@jobsub05.fnal.gov


-- Schedd: jobsub05.fnal.gov : <131.225.161.135:9615?... @ 04/24/24 16:36:40
 ID          OWNER            SUBMITTED     RUN_TIME HOST(S)
10774671.3   mu2epro         4/24 13:43   0+02:52:23 slot1_23@fnpc23026.fnal.gov
10774671.12  mu2epro         4/24 13:43   0+02:50:31 slot1_8@fnpc23027.fnal.gov
10774671.22  mu2epro         4/24 13:43   0+02:47:59 slot1_91@fnpc23115.fnal.gov
#+end_src
* tape upload: art files        
* tape upload: stntuples                                                     
- for now, keep stntuples disk-resident, back them up to tape   
- assume stntuples are located in /pnfs/mu2e/persistent/users/mu2epro/$project/stntuple/$dsid
- to do that : 
-  copy stntuple files to be saved to tape to XXX/tmp directory 
- run [[file:../scripts/upload_stn_dataset][grim/scripts/upload_stn_dataset]] : (start from reading comments on top of the script)
#+begin_src 
grim/scripts/upload_stn_dataset pipenu bmup4b0s56r0100/000
#+end_src
- next day, run mu2eDatasetLocation to assign tape locations to the uploaded files
- that can't be done immediately, because the files get Enstore locations assigned only after a while
- in SAM, the dataset assignment is done based on the file name, so for multi-fileset datasets, 
  can do the upload by fileset
#+begin_src
mu2eDatasetLocation --add=tape nts.mu2e.bmup4b0s56r0100.pipenu.stn
#+end_src 
* ------------------------------------------------------------------------------
* individual scripts in alphabetic order                                     
** [[file:../scripts/build_tarball.py][grim/scripts/build_tarball.py]]         : interface to Rob's gridexport                                                 
** [[file:../scripts/check_completed_job.py][grim/scripts/check_completed_job.py]]   : checks status of the completed grid job, reports failed segments              

   call signature:

   grim/scripts/check_competed_job.py --project=grim --dsid=cele0 --stage=s4 --job=sim  --gridid=

    - project: grim
    - dsid   : input dataset [10 char long]
    - gridid : grid job ID of the completed job
    - job    : job type , as defined by init_project.py 
    - stage  : job stage, as defined by init_project.py of this family (or group)

    stage and type parameters together define the fcl file configuring the job

    - relies on the presence of he job status files in ./tmp/$project/fcl/$dsid.$stage_$job/grid_job_status, 
      created by *submit_job.py* and updated by *grid_monitor.py*

    if there were failed segments, copies their FCL files into a directory to be used by gen_fcl.py 
    to create a FCL tarball for the recovery job:

    gen_fcl.py --recover=34566555

    submit_job.py --recover=34566555
    
** [[file:../scripts/check_pnfs_file_locality][grim/scripts/check_pnfs_file_locality]] : checks status of file in PNFS                                                 
   call signature:
#+begin_src
                grim/scripts/check_pnfs_file_locality full_file_name
#+end_src

   output:

   - 'ONLINE'              : file is on disk, but not on tape
   - 'NEARLINE'            : file is on tape, but not on disk
   - 'ONLINE_AND_NEARLINE' : file is on DISK and on tape

   example:

#+begin_src
grim/scripts/check_pnfs_file_locality /pnfs/mu2e/tape/phy-sim/dig/mu2e/rmce2s41b0/grim/art/73/bc/dig.mu2e.rmce2s41b0.grim.001000_00000005.art
ONLINE_AND_NEARLINE
#+end_src

** [[file:../scripts/concat_stn_dataset][grim/scripts/concat_stn_dataset]]       : concatenate stntuple dataset                                                  

** [[file:../scripts/copy_log_files.py][grim/scripts/copy_log_files.py]]        : copy log files of a grid job to /mu2e/data/users/$USER/$project               

** [[file:../scripts/clone_dataset_family.sh][grim/scripts/clone_dataset_family.sh]]  : create template files to generate new dataset family                          

   - call signature:  grim/scripts/clone_dataset_family.sh project family1 family2

     - project: project 
     - family1: existing family definition (in subdirectory $prokect/$family1)
     - family2: new family definition template, to be edited 

   - example: grim/scripts/clone_dataset_family.sh pbar2m bmum0b0 bmumcb0

** [[file:../scripts/gen_fcl.py][grim/scripts/gen_fcl.py]]               : interface to Andrei's generate_fcl                                            

    grim/scripts/gen_fcl.py --project=grim --dsid=cele0 --stage=s4 --job=sim [ --recover=step ]

    - project: grim
    - dsid   : dataset family - 5 first characters of the dataset ID
    - stage  : job stage, as defined by init_project.py of this family (or group)
    - job    : job name , as defined by init_project.py 
    - recover: say, '01', step, pattern added to the FCL tarball
               in a recovery more assume that the directory tmp/$project/fcl/$dsid.$stage_$job.$step 
               with a few FCL files corresponding to segments to be recovered already exists and populated ,
               so all one needs to to is to tar them up and copy the tarball to /pnfs
               
    generated fcls are copied to tmp/grim/fcl/... and tarball - to /pnfs/mu2e/resilient/users/$USER/$project/.

    assume the number of segments < 1000, if more than 1000 segments to be submitted, run 

    gen_fcl.py .... --fileset=001 [--first-subrun=....]

    by default, first-subrun=fileset*n_segments specified in init_project.py for this job

** [[file:../scripts/grid_time_ana.C][grim/scripts/grid_time_ana.C]]          : read data produced by parse_grid_logs.rb , plot histograms                    
** [[file:../scripts/grid_monitor.py][grim/scripts/grid_monitor.py]]          : displays and updates status of the jobs submitted by *submit_job.py*          

    grim/scripts/grid_monitor.py --project=su2020 [--delete=list] [--verbose=1]

    - project: su2020
    - delete : delete a list of comma-separated grid jobs, cleaning up the report. example:
#+begin_src
grim/scripts/grid_monitor.py --project=pbar2m --delete=37547802@jobsub03.fnal.gov,37548352,37548579
#+end_src

** [[file:../scripts/jobsub_gui.C][grim/scripts/jobsub_gui.C]]             : ROOT_based prototype of a GUI interface, redo with PyQT5 gui builder          

   temporary files in $PWD/tmp/grim
   
** [[file:../scripts/list_pnfs_files.py][grim/scripts/list_pnfs_files.py]]       : create 'catalogs' of temporary datasets to speed up the next stage submission 
** [[file:../scripts/parse_grid_logs.rb][grim/scripts/parse_grid_logs.rb]]       : parse timing information for timing etc analysis
** [[file:../scripts/print_config.py][grim/scripts/print_config.py]]          : print configuration of jobs for a given dataset family                        
example of the script output:
#+begin_src
/projects/mu2e/app/users/murat/grim>grim/scripts/print_config.py --project=grim --dsid=bmum0
-----------------------------------------------------------------------------------------------------------------------------------------------------
stage          job                   input DSID  N(seg) N(outputs)  output DSID      outputFnPattern                base FCL
-----------------------------------------------------------------------------------------------------------------------------------------------------
s1    sim                            bmum0s00b0    400       1       bmum0s11b0 sim.murat.bmum0s11b0 su2020/bmum0/s1_muon_beam_bmum0.fcl
s1    sim_e9                         bmum0s00b0   1000       1       bmum0s11b0 sim.murat.bmum0s11b0 su2020/bmum0/s1_muon_beam_bmum0.fcl
s1    concat                         bmum0s11b0     -1       1       bmum0s11b0 sim.murat.bmum0s11b0 su2020/bmum0/s1_concat_bmum0.fcl
s1    spmc_ele_filter                bmum0s11b0     -1       1       bmum0s16b0 sim.murat.bmum0s16b0 su2020/bmum0/s1_spmc_ele_filter_bmum0.fcl
s1    muon_beam_stn                  bmum0s11b0     -1       1       bmum0s11b0 nts.murat.bmum0s11b0 su2020/bmum0/s1_muon_beam_stn_bmum0.fcl
s1    stn_s16                        bmum0s16b0     -1       1       bmum0s16b0 nts.murat.bmum0s16b0 su2020/bmum0/s1_muon_beam_stn_bmum0.fcl
-----------------------------------------------------------------------------------------------------------------------------------------------------
s2    sim                            bmum0s11b0     -1       1       bmum0s21b0 sim.murat.bmum0s21b0 su2020/bmum0/s2_muon_beam_bmum0.fcl
s2    concat                         bmum0s21b0     -1       1       bmum0s21b0 sim.murat.bmum0s21b0 su2020/bmum0/s2_concat_bmum0.fcl
s2    sim_muo                        bmum0s11b0     -1       1       bmum0s27b0 sim.murat.bmum0s27b0 su2020/bmum0/s2_muon_beam_01_bmum0.fcl
s2    sim_ele                        bmum0s16b0     -1       1       bmum0s26b0 sim.murat.bmum0s26b0 su2020/bmum0/s2_muon_beam_02_bmum0.fcl
s2    spmc_ele_filter                bmum0s27b0     -1       1       bmum0s28b0 sim.murat.bmum0s28b0 su2020/bmum0/s2_spmc_ele_filter_bmum0.fcl
s2    stn_s26                        bmum0s26b0     -1       1       bmum0s26b0 nts.murat.bmum0s26b0 su2020/bmum0/s2_muon_beam_stn_bmum0.fcl
s2    stn_s28                        bmum0s28b0     -1       1       bmum0s28b0 nts.murat.bmum0s28b0 su2020/bmum0/s2_muon_beam_stn_bmum0.fcl
s2    muon_beam_stn                  bmum0s21b0     -1       1       bmum0s21b0 nts.murat.bmum0s21b0 su2020/bmum0/s2_mubeam_stn_bmum0.fcl
-----------------------------------------------------------------------------------------------------------------------------------------------------
s3    sim                            bmum0s21b0     -1       2       bmum0s31b0 sim.murat.bmum0s31b0 su2020/bmum0/s3_muon_beam_bmum0.fcl
                                                                     bmum0s32b0 sim.murat.bmum0s32b0
s3    sim_muo                        bmum0s27b0     -1       1       bmum0s37b0 sim.murat.bmum0s37b0 su2020/bmum0/s3_muon_beam_vd9_01_bmum0.fcl
s3    sim_vd9                        bmum0s21b0     -1       1       bmum0s3cb0 sim.murat.bmum0s3cb0 su2020/bmum0/s3_muon_beam_vd9_bmum0.fcl
s3    add_proton_time_map_s3c        bmum0s3cb0     -1       1       bmum0s3cb0 sim.murat.bmum0s3cb0 su2020/bmum0/s3_add_proton_time_map_s3c_bmum0.fcl
s3    spmc_ele_filter                bmum0s37b0     -1       1       bmum0s39b0 sim.murat.bmum0s39b0 su2020/bmum0/s3_spmc_ele_filter_bmum0.fcl
s3    spmc_muo_filter                bmum0s37b0     -1       1       bmum0s3ab0 sim.murat.bmum0s3ab0 su2020/bmum0/s3_spmc_muo_filter_bmum0.fcl
s3    sim_ele                        bmum0s26b0     -1       1       bmum0s36b0 sim.murat.bmum0s36b0 su2020/bmum0/s3_muon_beam_vd9_02_bmum0.fcl
s3    sim_ele_28                     bmum0s28b0     -1       1       bmum0s38b0 sim.murat.bmum0s38b0 su2020/bmum0/s3_muon_beam_vd9_02_bmum0.fcl
s3    resample_ele                   bmum0s26b0     -1       1       bmum0s36b0  sim.mu2e.bmum0s36b0 su2020/bmum0/s3_resample_ele_bmum0.fcl
s3    stn_s31                        bmum0s31b0     -1       1       bmum0s31b0 nts.murat.bmum0s31b0 su2020/bmum0/s3_stn_s31_bmum0.fcl
s3    stn_s32                        bmum0s32b0     -1       1       bmum0s32b0 nts.murat.bmum0s32b0 su2020/bmum0/s3_stn_s32_bmum0.fcl
s3    stn_s3c                        bmum0s3cb0     -1       1       bmum0s3cb0 nts.murat.bmum0s3cb0 su2020/bmum0/s3_stn_s3c_bmum0.fcl
s3    muon_beam_stn                  bmum0s37b0     -1       1       bmum0s37b0 nts.murat.bmum0s37b0 su2020/bmum0/s3_muon_beam_stn_bmum0.fcl
-----------------------------------------------------------------------------------------------------------------------------------------------------
s4    sim_muo_vd10                   bmum0s37b0     -1       1       bmum0s47b0 sim.murat.bmum0s47b0 su2020/bmum0/s4_sim_muo_vd10_bmum0.fcl
s4    spmc_muo_filter                bmum0s47b0     -1       1       bmum0s4bb0 sim.murat.bmum0s4bb0 su2020/bmum0/s4_spmc_muo_filter_bmum0.fcl
s4    muon_beam_stn                  bmum0s47b0     -1       1       bmum0s47b0 nts.murat.bmum0s47b0 su2020/bmum0/s4_muon_beam_stn_bmum0.fcl
-----------------------------------------------------------------------------------------------------------------------------------------------------
s5    resample_vd9_to_mother_s36     bmum0s36b0     -1       1       bmum0s56b0 sim.murat.bmum0s56b0 su2020/bmum0/s5_resample_vd9_to_mother_s36_bmum0.fcl
s5    resample_vd9_to_mother_s3a     bmum0s3ab0     -1       1       bmum0s5ab0 sim.murat.bmum0s5ab0 su2020/bmum0/s5_resample_vd9_to_mother_s3a_bmum0.fcl
s5    resample_vd9_to_mother_s38     bmum0s38b0     -1       1       bmum0s58b0 sim.murat.bmum0s58b0 su2020/bmum0/s5_resample_vd9_to_mother_bmum0.fcl
s5    resample_vd9_to_mother_s39     bmum0s39b0     -1       1       bmum0s59b0 sim.murat.bmum0s59b0 su2020/bmum0/s5_resample_vd9_to_mother_bmum0.fcl
s5    resample_vd10_to_mother        bmum0s4bb0      1       1       bmum0s5bb0 sim.murat.bmum0s5bb0 su2020/bmum0/s5_resample_vd10_to_mother_bmum0.fcl
s5    stn_s56                        bmum0s56b0     -1       1       bmum0s56b0 nts.murat.bmum0s56b0 su2020/bmum0/s5_stn_bmum0.fcl
s5    stn_s58                        bmum0s58b0     -1       1       bmum0s58b0 nts.murat.bmum0s58b0 su2020/bmum0/s5_stn_bmum0.fcl
s5    stn_s59                        bmum0s59b0     -1       1       bmum0s59b0 nts.murat.bmum0s59b0 su2020/bmum0/s5_stn_bmum0.fcl
s5    stn_s5a                        bmum0s5ab0     -1       1       bmum0s5ab0 nts.murat.bmum0s5ab0 su2020/bmum0/s5_stn_bmum0.fcl
s5    stn_s5b                        bmum0s5bb0     -1       1       bmum0s5bb0 nts.murat.bmum0s5bb0 su2020/bmum0/s5_stn_bmum0.fcl
-----------------------------------------------------------------------------------------------------------------------------------------------------
#+end_src
** [[file:../scripts/submit_job.py][grim/scripts/submit_job.py]]            : grid job submission tool, today it is an inteface to mu2eprodsys              
#+begin_src 
    call signature:

    grim/scripts/submit_job.py --project=grim --dsid=cele0 --stage=s4 --job=sim  [--recover=step] [--doit=./d//]

    - project: grim
    - dsid   : dataset family (5 first characters of the dataset ID)
    - stage  : job stage, as defined by init_project.py of this family (or group)
    - job    : job type , as defined by init_project.py 
    - recover: recovery step - if defined, the corresponding "recovery" FCL tarball will be used for submission
               if '--recover' parameter is specified, nothing else , except --doit is needed, for example:

               grim/scripts/submit_job.py --recover=39134961 --doit=.

    stage and type parameters together define the fcl file configuring the job

    - doit   : 
       - 'd'                      : Andrei's dry_run mode
       - 'yes' (or anything else) : submit the job 

    grim/scripts/submit_job.py stores information about the submitted job into 

#+end_src

** [[file:../scripts/upload_grid_output.sh][grim/scripts/upload_grid_output.sh]]    : upload output of a grid job to tape
** [[file:../scripts/validate_dcache_files.sh][grim/scripts/validate_dcache_files.sh]] : extracts inputs defind in a given FCL file, checks if they are readable     
* ------------------------------------------------------------------------------
